# Lite RT

[litert](https://ai.google.dev/edge/litert)

LiteRT (short for Lite Runtime), formerly known as TensorFlow Lite, is Google's high-performance **runtime for on-device AI**. You can find ready-to-run LiteRT models for a wide range of ML/AI tasks, or convert and run TensorFlow, PyTorch, and JAX models to the TFLite format using the AI Edge conversion and optimization tools.

- **Optimized for on-device machine learning**: LiteRT addresses five key ODML constraints: latency (there's no round-trip to a server), privacy (no personal data leaves the device), connectivity (internet connectivity is not required), size (reduced model and binary size) and power consumption (efficient inference and a lack of network connections).