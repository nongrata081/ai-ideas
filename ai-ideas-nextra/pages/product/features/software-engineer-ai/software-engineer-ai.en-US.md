# software engineer AI

use [bolt.new](bolt.new) as an inspiration

- chat with LM on the left side
- web-container with dev environment on the right-side
    - code IDE
    - browser with preview
    - terminal
    - deploy

---

Step 1. chatUI
![](./img/boltnew-step-1-chatUI.png)

Step 2. Make a prompt. Boot webcontainer with code IDE & browser.
![](./img/boltnew-step-2-prompt-webcontainer.png)

Step 3. Preview
![](./img/boltnew-step-3-preview.png)

![](./img/boltnew-step-3-preview-2.png)

---

(Local open-source)

- Possible implementation - [**OpenHands github**](https://github.com/All-Hands-AI/OpenHands) / [**all-hands.dev**](https://www.all-hands.dev/)
    - paper [OpenDevin: An Open Platform for AI Software Developers as Generalist Agents](https://arxiv.org/abs/2407.16741)
    - [Youtube Video 1](https://www.youtube.com/watch?v=Q3DyeIV96tY)
    - [Youtube Video 2](https://www.youtube.com/watch?v=FCqsjwfmrmM)
    - [Youtube Video 3](https://www.youtube.com/watch?v=dKD4a_sv69o)
    - Context
        - [gh issue: ollama](https://github.com/All-Hands-AI/OpenHands/issues/3960)
        - [old: Using Ollama](https://github.com/All-Hands-AI/OpenHands/discussions/509)
        - [old2: ollama](https://github.com/All-Hands-AI/OpenHands/discussions/2088)
        - [Local LLM Guide](https://github.com/All-Hands-AI/OpenHands/commit/08a2dfb01af1aec6743f5e4c23507d63980726c0)
        - [docs: LLM Backends](https://docs.all-hands.dev/modules/usage/llms)
    - Where is easy Ollama integration? With easy local model switching?

---

