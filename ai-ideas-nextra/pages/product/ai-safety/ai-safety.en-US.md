# AI Safety

## safety-eval wildteaming & wildguard

what about it? extract & incorporate from papers, github

- [ ] [wildteaming](http://localhost:3000/ai-tools/LLM/evaluation/savety-eval#wildteaming) 
- [ ] [wildguard](/ai-tools/LLM/evaluation/savety-eval#wildguard)


---

- [Managing extreme AI risks amid rapid progress](https://managing-ai-risks.com/)
    - [Paper](https://arxiv.org/pdf/2310.17688)
- [Towards Guaranteed Safe AI: A Framework for Ensuring Robust and Reliable AI Systems](https://www.alignmentforum.org/posts/LkECxpbjvSifPfjnb/towards-guaranteed-safe-ai-a-framework-for-ensuring-robust-1)
    - [Paper](https://arxiv.org/abs/2405.06624)


- [How to hack the simulation](https://www.researchgate.net/publication/364811408_How_to_Hack_the_Simulation)
